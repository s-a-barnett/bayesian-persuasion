
var modelName = 'mas-het-speakers-adding';

var inferenceParams = {
  experiment: argv.experiment,
  samples: argv.samples,
  burn: argv.burn,
  lag: argv.lag,
  verbose: (argv.verbose == 'true'), // converting str to bool,
  chain: _.isFinite(argv.chain) ? argv.chain : 1,
  out: argv.out
};

var testSamples = _.isFinite(argv.testSamples) ? argv.testSamples : 10000;

// prior over rsa hom model parameters
var groupPrior = function(model) {
  var params = model == 'mas' ? {
    gradient : uniformDrift({a: 0, b: 10, width: 1}),
    threshold : uniformDrift({a: -1, b: 1, width: .1}),
  } : model == 'aa' ? {
    gradient : uniformDrift({a: 0, b: 10, width: 1}),
    threshold : 0.0,
  } : {
    gradient: 0,
    threshold: 0,
  };
  return params;
};

var getScore = function(datum, params) {
  // read single observation from overall observations
  var stickLength   = _.toNumber(datum[1]);
  var subjectBelief = _.toNumber(datum[2]);

  // compute belief in idealized model
  var mean = shared.getAAAddingScore('long', stickLength, params);
  var noiseDist = Gaussian({mu: Math.exp(mean), sigma: params.logitSigma});

  // in Gelman et al. notation, this is log(p(y_i | Î¸^s))
  //   for i-th observation, s-th posterior sample
  return _.max([Math.log(0.01), noiseDist.score(subjectBelief)]);
};

var getLevels = function(means, obs) {
  var speakerSticks = map(function(o){return o[3] < 0.8 ? 'less' : o[3];}, obs);

  return map(function(stick) {
    return categorical({ps: means[stick], vs: ['aa', 'mas']})
  }, speakerSticks);
};

var levelDist = function(means, obs) {
  return Infer({
    method: 'forward',
    samples: testSamples,
    model: function() {
      return getLevels(means, obs);
    }
  })
};

var mixtureScore = function(means, sharedParams, groupParams, obs, test) {
  var pointScores = mapData({data: obs}, function(datum) {
    var speakerStick = datum[3] < 0.8 ? 'less' : datum[3];
    var pointScore = shared.logSumExp(map2(function(level, idx) {
      var datumParams = extend(sharedParams, groupParams[level], {level});
      var pointLevelScore = getScore(datum, datumParams);
      var levelPriorScore = Math.log(means[speakerStick][idx]);
      return pointLevelScore + levelPriorScore;
    }, ['aa', 'mas'], [0, 1]));
    if (!test) {
      query.add('p' + datum[0], pointScore);
      factor(pointScore);
    };

    return pointScore;
  });
  return sum(pointScores);
};

// var batchScore = function(levels, sharedParams, groupParams, obs, test) {
//   var pointScores = mapData({data: obs}, function(datum, i) {
//     var level = levels[i].toString();
//     var datumParams = extend(sharedParams, groupParams[level], {level});
//     var pointScore = getScore(datum, datumParams);

//     if (!test) {
//       query.add('p' + datum[0], pointScore);
//       factor(pointScore);
//     };

//     return pointScore;
//   });
//   return sum(pointScores);
// };

var train = function(obs) {
  return Infer({
    method: 'MCMC',
    samples: inferenceParams.samples,
    burn: inferenceParams.burn,
    lag: inferenceParams.lag,
    verbose: inferenceParams.verbose,
    model: function() {
      var logitSigma = 0.3
      var sharedParams = {logitSigma};

      var groupParams = {
        'aa' : groupPrior('aa'),
        'mas' : groupPrior('mas'),
      };

      var speakerSticks = map(function(o){return o[3];}, obs);
      var means = {
        '0.9' : _.values(dirichletDrift({alpha: Vector([1, 1])}).data),
        '0.8' : _.values(dirichletDrift({alpha: Vector([1, 1])}).data),
        'less' : _.values(dirichletDrift({alpha: Vector([1, 1])}).data),
      };
      var totalScore = mixtureScore(means, sharedParams, groupParams, obs, false);

      query.add('mas' + '_gradient', groupParams['mas'].gradient);
      query.add('mas' + '_threshold', groupParams['mas'].threshold);
      query.add('aa' + '_gradient', groupParams['aa'].gradient);

      query.add('groupWeight-aa-0.9', means['0.9'][0]);
      query.add('groupWeight-aa-0.8', means['0.8'][0]);
      query.add('groupWeight-aa-less', means['less'][0]);

      query.add('groupWeight-mas-0.9', means['0.9'][1]);
      query.add('groupWeight-mas-0.8', means['0.8'][1]);
      query.add('groupWeight-mas-less', means['less'][1]);

      query.add('logitSigma', logitSigma);

      query.add('score', totalScore);
      query.add('params', JSON.stringify(extend({sharedParams}, {groupParams}, {means})));

      return query;
    }})
};

if (argv.test == 'true') {
  var obs = csv.read('input/' + argv.experiment + '_data_test_' + argv.fold + '.csv').slice(1, -1);

  var mleString = argv.mleString;
  var mleParams = JSON.parse(mleString);

  var groupParams = mleParams.groupParams;
  var sharedParams = mleParams.sharedParams;

  if (argv.maxScore == 'true') {
    var drawScore = function() {
      var levels = getLevels(mleParams.means, obs);
      return batchScore(levels, sharedParams, groupParams, obs, true, {});
    };
    var maxScore = _.max(repeat(testSamples, drawScore))
    console.log(maxScore);
  } else {
    var expectedScore = mixtureScore(mleParams.means, sharedParams, groupParams, obs);
    console.log(expectedScore);
  };

} else {
  var data = _.isFinite(argv.fold) ? argv.experiment + '_data_train_' + argv.fold + '.csv' : argv.experiment + '_data_full.csv';
  var obs = csv.read('input/' + data).slice(1, -1);
  // open pointScore file
  var chainFold = "c" + inferenceParams.chain + "f" + argv.fold + argv.experiment;

  // write posterior distribution to new file
  csv.writeDistTable(train(obs), "param,val", inferenceParams.out + "/" + modelName + "-params-posterior_" + chainFold + ".csv");
};
