var inferenceParams = {
  experiment: argv.experiment,
  samples: argv.samples,
  burn: argv.burn,
  lag: argv.lag,
  verbose: (argv.verbose == 'true'), // converting str to bool
  chain: _.isFinite(argv.chain) ? argv.chain : 1,
  out: argv.out
};

// prior over rsa hom model parameters
var groupPrior = function(model) {
  var params = model == 'mas' ? {
              gradient : exponential({a: 0.01}),
              threshold : uniform({a: 0, b: 1}),
            } : model == 'aa' ? {
              gradient : exponential({a: 0.01}),
              threshold : 0.5,
            } : {
              gradient: 0.01,
              threshold: 0,
            };
  return params;
};

var masPP = function(obs) {

  var observe_fn = function(datum, params) {
    // read single observation from overall observations
    var stickLength = _.toNumber(datum[1]);
    var subjectBelief = _.toNumber(datum[2]);

    // compute belief in idealized model
    var mean = shared.getAAAveragingScore('long', stickLength, params) ;

    // mu represents the mean of the normal distribution given by the logit
    //   of the model belief
    var mu = mean - Math.log1p(-Math.exp(mean));

    var noiseDist = params.level == 'noise' ?
      Uniform({a: 0., b: 1.}) :
      // LogitNormal({mu: mu, sigma: params.logitSigma, a: 0., b: 1.});
      Gaussian({mu: Math.exp(mean), sigma: params.logitSigma});

    // in Gelman et al. notation, this is log(p(y_i | Î¸^s))
    //   for i-th observation, s-th posterior sample
    var pointScore = noiseDist.score(subjectBelief);
    globalStore.totalScore += pointScore;

    var iter = shared.iterationTracker() / obs.length;
    var floor_iter = _.floor(iter);

    // write pointScore into separate external file
    if (shared.isRecordedIter(floor_iter, inferenceParams.burn, inferenceParams.lag)) {
      if (floor_iter + 1 == iter + (1/obs.length)) {
        // console.log(globalStore.totalScore);
      };
    };

    factor(pointScore);

    return noiseDist;
  };

  return Infer({method: 'MCMC',
                samples: inferenceParams.samples,
                burn: inferenceParams.burn,
                lag: inferenceParams.lag,
                verbose: inferenceParams.verbose,
                model: function() {

    var logitSigma = uniformDrift({a: 0, b: 1, width: 0.1});
    var sharedParams = {logitSigma};

    var groupParams = {
      'noise' : groupPrior('noise'),
      'aa' : groupPrior('aa'),
      'mas' : groupPrior('mas')
    };

    var speakerSticks = map(function(o){return o[3];}, obs);
    var means = {
      '0.9' : _.values(dirichletDrift({alpha: Vector([1, 1, 1])}).data),
      '0.8' : _.values(dirichletDrift({alpha: Vector([1, 1, 1])}).data),
      '0.7' : _.values(dirichletDrift({alpha: Vector([1, 1, 1])}).data),
    };

    var levels = map(function(stick) {
      return categorical({ps: means[stick], vs: ['noise', 'aa', 'mas']})
    }, speakerSticks);

    globalStore.totalScore = 0;
    var noiseDists = mapData({data: obs}, function(datum, i) {
      var level = levels[i].toString();
      var datumParams = extend(sharedParams, groupParams[level], {level});

      var noiseDist = observe_fn(datum, datumParams);
      return noiseDist;
    });

    var beliefs = map(function(d) {return sample(d)}, noiseDists);
    var gameids = map(function(o){return o[0];}, obs);

    return _.zipObject(gameids, beliefs);
  }})
};

// read observations from csv file (slice to skip header and empty final line)
var obs = csv.read('input/' + argv.experiment + '_data_no0.2_0.4.csv').slice(1, -1);

// write posterior distribution to new file
csv.writeJoint(masPP(obs), inferenceParams.out + "/mas-pp-params-posterior_" + argv.experiment + "_" + inferenceParams.chain + ".csv");
