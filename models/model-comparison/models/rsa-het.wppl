var modelName = 'rsa-het';

var inferenceParams = {
  experiment: argv.experiment,
  samples: argv.samples,
  burn: argv.burn,
  lag: argv.lag,
  verbose: (argv.verbose == 'true'), // converting str to bool,
  chain: _.isFinite(argv.chain) ? argv.chain : 1,
  out: argv.out
};

// prior over rsa het model parameters
var groupPrior = function(model) {
  var params = model == 'J1' ? {
    nSticks : uniformDraw([5]),  // number of sticks modelled by judge
    agentBias : uniformDrift({a: 0, b: 10, width: 1}),   // fixed value of judge for S1/S2 speaker
  } : model == 'J0' ? {
    nSticks : uniformDraw([5]),  // number of sticks modelled by judge
    agentBias : 0,
  } : {
    nSticks: 5,
    agentBias: 0,
  };
  return extend(params, {getJ1Score: shared.getJ1Score_generator(params)});
};

var getScore = function(datum, params) {
  // read single observation from overall observations
  var stickLength   = _.toNumber(datum[1]);
  var subjectBelief = _.toNumber(datum[2]);

  // compute belief in idealized model
  var mean = params.level == 'J1' ?
      params.getJ1Score('long', stickLength, params) :
      params.level == 'J0' ?
      shared.getJ0Score('long', stickLength, params) :
      console.error('unknown level', params.level);

  var noiseDist = Gaussian({mu: Math.exp(mean) + params.offset, sigma: params.sigma});
  return _.max([Math.log(0.01), noiseDist.score(subjectBelief)]);
};

var mixtureScore = function(groupWeight, sharedParams, groupParams, obs) {
  var pointScores = mapData({data: obs}, function(datum) {
    var pointScore = shared.logSumExp(map2(function(level, idx) {
      var datumParams = extend(sharedParams, groupParams[level], {level});
      var pointLevelScore = getScore(datum, datumParams);
      var levelPriorScore = Math.log(groupWeight[idx]);
      return pointLevelScore + levelPriorScore;
    }, ['J0', 'J1'], [0, 1]));

    query.add('pointscore_' + datum[0], pointScore);
    factor(pointScore);

    return pointScore;
  });
  return sum(pointScores);
};

var train = function(obs) {
  return Infer({
    method: 'MCMC',
    samples: inferenceParams.samples,
    burn: inferenceParams.burn,
    lag: inferenceParams.lag,
    verbose: inferenceParams.verbose,
    model: function() {
      var groupWeightA = uniformDrift({a: 0, b: 1, width: .1});
      var groupWeight = [1 - groupWeightA, groupWeightA];
      var sigma = 0.3;
      var offset = uniformDrift({a: -0.5, b: 0.5, width: 0.05});
      var sharedParams = {groupWeight, sigma, offset};

      var groupParams = {
        'J0' : groupPrior('J0'),
        'J1' : groupPrior('J1')
      };
      var totalScore = mixtureScore(groupWeight, sharedParams, groupParams, obs);

      query.add('J0nSticks', groupParams['J0'].nSticks);
      query.add('J1nSticks', groupParams['J1'].nSticks);
      query.add('J1agentBias', groupParams['J1'].agentBias);
      query.add('groupWeight-J0', sharedParams.groupWeight[0]);
      query.add('groupWeight-J1', sharedParams.groupWeight[1]);
      query.add('sigma', sigma);
      query.add('offset', sharedParams.offset);

      query.add('likelihood', totalScore);
      query.add('params', JSON.stringify(extend({sharedParams}, {groupParams})));

      return query;
    }})
};

var obs = csv.read('input/' + argv.experiment + '_data_full.csv').slice(1, -1);
var chain = "c" + inferenceParams.chain + argv.experiment;

// write posterior distribution to new file
csv.writeDistTable(train(obs), "param,val", inferenceParams.out + "/" + modelName + "-params-posterior_" + chain + ".csv");
