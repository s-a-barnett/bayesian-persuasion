var modelName = 'rsa-hom';

var inferenceParams = {
  experiment: argv.experiment,
  samples: argv.samples,
  burn: argv.burn,
  lag: argv.lag,
  verbose: (argv.verbose == 'true'), // converting str to bool,
  chain: _.isFinite(argv.chain) ? argv.chain : 1,
  out: argv.out
};

// prior over rsa hom model parameters
var paramsPrior = function() {
  // number of sticks modelled by judge
  var nSticks = uniformDraw([5]);
  // fixed value of judge for S1 speaker
  var agentBias = uniformDrift({a: 0, b: 10, width: 1});
  var logitSigma = 0.3
  // determines whether population treated as J0 or J1

  return {
    'nSticks': nSticks,
    'agentBias': agentBias,
    'logitSigma': logitSigma,
    'level': 'J1'
  };
};

var batchScore = function(params, obs, test) {
  var pointScores = mapData({data: obs}, function(datum) {
    var stickLength   = _.toNumber(datum[1]);
    var subjectBelief = _.toNumber(datum[2]);
    var mean = params.level == 'J1' ?
          params.getJ1Score('long', stickLength, params) :
          shared.getJ0Score('long', stickLength, params) ;

    var noiseDist = Gaussian({mu: Math.exp(mean) + params.offset, sigma: params.logitSigma});
    // in Gelman et al. notation, this is log(p(y_i | Î¸^s))
    //   for i-th observation, s-th posterior sample
    var pointScore = _.max([Math.log(0.01), noiseDist.score(subjectBelief)])

    if (!test) {
      query.add('p' + datum[0], pointScore);
      query.add('predictionFor' + datum[0] + '@' + stickLength + '=' + subjectBelief, Math.exp(mean));
      factor(pointScore);
    };

    return pointScore;
  });
  return sum(pointScores);
};

var train = function(obs) {
  return Infer({
    method: 'MCMC',
    samples: inferenceParams.samples,
    burn: inferenceParams.burn,
    lag: inferenceParams.lag,
    verbose: inferenceParams.verbose,
    model: function() {

      var rawParams = paramsPrior();
      var params = extend(rawParams, {
        offset: uniformDrift({a: -.5, b: .5, width: 0.05}),
        getJ1Score: shared.getJ1Score_generator(rawParams)
      });
      console.log(params)
      var totalScore = batchScore(params, obs, false);
      console.log(totalScore)
      query.add('nSticks', rawParams.nSticks);
      query.add('agentBias', rawParams.agentBias);
      query.add('logitSigma', rawParams.logitSigma);
      query.add('level', rawParams.level);

      query.add('score', totalScore);
      query.add('params', JSON.stringify(rawParams));

      return query;
    }
  })
};

if (argv.test == 'true') {
  var obs = csv.read('input/' + argv.experiment + '_data_test_' + argv.fold + '.csv').slice(1, -1);

  var mleString = argv.mleString;
  var mleParams = JSON.parse(mleString);

  var params = extend(mleParams, {getJ1Score: shared.getJ1Score_generator(mleParams)});

  var expectedScore = batchScore(params, obs, true, {})

  console.log(expectedScore);

} else {
  var data = _.isFinite(argv.fold) ? argv.experiment + '_data_train_' + argv.fold + '.csv' : argv.experiment + '_data_full.csv';
  var obs = csv.read('input/' + data).slice(1, -1);
  // open pointScore file
  var chainFold = "c" + inferenceParams.chain + "f" + argv.fold + argv.experiment;

  // write posterior distribution to new file
  csv.writeDistTable(train(obs), "param,val", inferenceParams.out + "/" + modelName + "-params-posterior_" + chainFold + ".csv");
};
