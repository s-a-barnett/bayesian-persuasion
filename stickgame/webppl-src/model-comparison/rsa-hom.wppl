var inferenceParams = {
  samples: argv.samples,
  burn: argv.burn,
  verbose: (argv.verbose == 'true') // converting str to bool
};

// prior over rsa hom model parameters
var paramsPrior = function() {
  // number of sticks modelled by judge
  var nSticks = uniformDraw([2, 3, 4, 5]);
  // fixed value of judge for S1 speaker
  var agentBias = 10 * beta({a: 2, b: 5});
  // variance for mean noise
  var logitSigma = exponential({a: 10});
  // proportion of participants that are J1 judges in the population
  var level = flip(.5) ? 'J1' : 'J0';//levelMixture = beta({a: 1, b: 1});
  return {
    'nSticks': nSticks,
    'agentBias': agentBias,
    'logitSigma': logitSigma,
    'level': level
  };
};

var rsaHom = function(obs, output_handle) {
  var observe_fn = function(datum, params) {
      // read single observation from overall observations
    var stickLength = _.toNumber(datum[0])
    var subjectBelief = _.toNumber(datum[1])
    var evidence = [{'agentID': 'agent0', stickLength: [stickLength]}];
    // determine whether observation treated by J0 or J1
    
    // compute belief in idealized model
    var judgeDist = params.level == 'J1' ?
        J1(evidence, params) :
        J0(_.flatten(_.map(evidence, 'stickLength')), params);
    var mean = marginalize(judgeDist, "isLong").score("long");
    // mu represents the mean of the normal distribution given by the logit
    //   of the model belief
    var mu = mean - Math.log1p(-Math.exp(mean));
    // people respond with 0's and 1's, so you have to make (a, b) broader than (0, 1)
    // thought: choose a distribution with a fatter tail? truncated cauchy?

    var noiseDist = LogitNormal({mu: mu, sigma: params.logitSigma, a: -0.001, b: 1.001});

    // in Gelman et al. notation, this is log(p(y_i | Î¸^s))
    //   for i-th observation, s-th posterior sample
    var pointScore = noiseDist.score(subjectBelief);
//    console.log(pointScore)
    // write pointScore into separate external file
    // csv.writeLine(_.values(params).toString() + "," + datum.toString() + "," + pointScore,
    //               output_handle);

    // factor and go to remaining observations
    factor(pointScore);
  };

  return Infer({method: 'MCMC', samples: inferenceParams.samples,
    burn: inferenceParams.burn, verbose: inferenceParams.verbose, model: function() {

    var params = paramsPrior();
      console.log(params);
      console.log('here')
      mapData({data: obs}, function(datum) {
        //console.log(datum)
        observe_fn(datum, params);
      });
    return params
  }})
};

// read observations from csv file
var obs = rest(csv.read('data/rsa-hom-data.csv'));

// open pointScore file
var output_handle = csv.open("results/rsa-hom-scores.csv");
csv.writeLine("nSticks,agentBias,logitSigma,levelMixture,stickLength,subjectBelief,score", output_handle);
// write posterior distribution to new file
csv.writeJoint(rsaHom(obs, output_handle), "results/rsa-hom-params-posterior.csv");
csv.close(output_handle);
